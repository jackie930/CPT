{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "282f691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Using cached rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Collecting datasets==1.4.1\n",
      "  Using cached datasets-1.4.1-py3-none-any.whl (186 kB)\n",
      "Collecting transformers==4.4.2\n",
      "  Using cached transformers-4.4.2-py3-none-any.whl (2.0 MB)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.4.1) (3.7.0)\n",
      "Collecting tqdm<4.50.0,>=4.27\n",
      "  Using cached tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.4.1) (0.70.12.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.4.1) (1.1.5)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.4.1) (2021.4.0)\n",
      "Collecting huggingface-hub==0.0.2\n",
      "  Using cached huggingface_hub-0.0.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.4.1) (1.19.2)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.4.1) (0.3.4)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.4.1) (5.0.0)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.4.1) (0.8)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-2.0.2-cp36-cp36m-manylinux2010_x86_64.whl (243 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.4.1) (2.26.0)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.3.1-py3-none-any.whl (9.7 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.4.2) (2020.11.13)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.4.2) (20.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from rouge) (1.15.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets==1.4.1) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets==1.4.1) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets==1.4.1) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets==1.4.1) (1.26.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata->datasets==1.4.1) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata->datasets==1.4.1) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging->transformers==4.4.2) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->datasets==1.4.1) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->datasets==1.4.1) (2021.1)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers==4.4.2) (1.0.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers==4.4.2) (7.1.2)\n",
      "Installing collected packages: tqdm, filelock, xxhash, tokenizers, sacremoses, huggingface-hub, transformers, rouge, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.62.2\n",
      "    Uninstalling tqdm-4.62.2:\n",
      "      Successfully uninstalled tqdm-4.62.2\n",
      "Successfully installed datasets-1.4.1 filelock-3.3.1 huggingface-hub-0.0.2 rouge-1.0.1 sacremoses-0.0.46 tokenizers-0.10.3 tqdm-4.49.0 transformers-4.4.2 xxhash-2.0.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge datasets==1.4.1 transformers==4.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a7edc9",
   "metadata": {},
   "source": [
    "## preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e454f1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = './demo_data/SUMMARY.hk01meta'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6fb88461",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data process \n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "df_article_summary_full = pd.read_parquet('../../../data/meta_description.parquet', engine='pyarrow')\n",
    "\n",
    "df_article_summary_full[['original_text','meta_descrption']].to_csv('./demo_data/SUMMARY.hk01meta/total.csv',index=False)\n",
    "\n",
    "total_data = pd.read_csv('./demo_data/SUMMARY.hk01meta/total.csv')\n",
    "x = total_data[-total_data['meta_descrption'].isnull()]\n",
    "x.columns = ['article','summarization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0401f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use csv file to test \n",
    "x[:15000].to_csv(os.path.join(path,'train.csv'),index=False,encoding='utf-8')\n",
    "x[15000:].to_csv(os.path.join(path,'test.csv'),index=False,encoding='utf-8')\n",
    "x[15000:].to_csv(os.path.join(path,'dev.csv'),index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff454fd",
   "metadata": {},
   "source": [
    "## run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838aeab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e7241949f0d489c0\n",
      "Reusing dataset csv (/home/ec2-user/.cache/huggingface/datasets/csv/default-e7241949f0d489c0/0.0.0/2a88c45fed596f9421a2e7f74ab1a3cd012ef75210a5dc1950e8d60ca8d9c66c)\n",
      "dataset:  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'summarization'],\n",
      "        num_rows: 15000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'summarization'],\n",
      "        num_rows: 875\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'summarization'],\n",
      "        num_rows: 875\n",
      "    })\n",
      "})\n",
      "10/20/2021 06:52:50 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "10/20/2021 06:52:50 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='output/hk01meta/1', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=True, evaluation_strategy=<IntervalStrategy.EPOCH: 'epoch'>, prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, logging_dir='runs/Oct20_06-52-50_ip-172-16-20-27', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, save_strategy=<IntervalStrategy.NO: 'no'>, save_steps=500, save_total_limit=None, no_cuda=False, seed=1000, fp16=False, fp16_opt_level='O1', fp16_backend='auto', fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='output/hk01meta/1', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=[], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, sortish_sampler=False, predict_with_generate=True)\n",
      "loading file https://huggingface.co/fnlp/cpt-large/resolve/main/vocab.txt from cache at /home/ec2-user/.cache/huggingface/transformers/0a6abd40606daaad5f23a8e9f2127800b25ad27f84e5cd995f9d4d299bb3a9ed.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
      "loading file https://huggingface.co/fnlp/cpt-large/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/fnlp/cpt-large/resolve/main/special_tokens_map.json from cache at /home/ec2-user/.cache/huggingface/transformers/8510c6f46587f7734a8c4aa6e9a2b89fba9b4a645bea86f08c43775404b230b8.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/fnlp/cpt-large/resolve/main/tokenizer_config.json from cache at /home/ec2-user/.cache/huggingface/transformers/5eb8926c0b2e4f9ab219d0754b9165d5c58ee645bea0636d8ae73a74d6a3c41b.4930bdcbc6f75dead7cdeadc249fdb55dcb3cd75bdcee68ee5fcd8aeb6e6e359\n",
      "loading file https://huggingface.co/fnlp/cpt-large/resolve/main/tokenizer.json from cache at None\n",
      "loading configuration file https://huggingface.co/fnlp/cpt-large/resolve/main/config.json from cache at /home/ec2-user/.cache/huggingface/transformers/ca23881be31fba3198d70c612a80b0f9c4be010844bbc7b3f043a48cee11538f.3365f594545e72ade8bd65f05c77ab679e4832c781f0150a2ed9e92696c5718e\n",
      "Model config BartConfig {\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 101,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"decoder_start_token_id\": 102,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 24,\n",
      "  \"eos_token_id\": 102,\n",
      "  \"forced_eos_token_id\": 102,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.4.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/fnlp/cpt-large/resolve/main/pytorch_model.bin from cache at /home/ec2-user/.cache/huggingface/transformers/d83412fb9f1aa74de5ad90d00f38c7e58e1bd64f4e6da01b8ae21eb23a1d56c5.679c9b4dda27681a4294e619af15d96605d0400a5a3d09db583af48c901eba02\n",
      "All model checkpoint weights were used when initializing CPTForConditionalGeneration.\n",
      "\n",
      "All the weights of CPTForConditionalGeneration were initialized from the model checkpoint at fnlp/cpt-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CPTForConditionalGeneration for predictions without further training.\n",
      "input shape: ---- 512\n",
      "  0%|                                                    | 0/15 [00:00<?, ?ba/s]input shape: ---- 512\n",
      "  7%|██▉                                         | 1/15 [00:11<02:44, 11.72s/ba]"
     ]
    }
   ],
   "source": [
    "#!python run_gen.py --model_path 'fnlp/cpt-base' --dataset adgen --data_dir demo_data\n",
    "!python run_gen_v2.py --model_path 'fnlp/cpt-large' --dataset hk01meta --data_dir demo_data --epoch '10' --batch_size '4' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1fc83",
   "metadata": {},
   "source": [
    "## rouge score calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5707e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8b72df5a2fc7b575\n",
      "Reusing dataset csv (/home/ec2-user/.cache/huggingface/datasets/csv/default-8b72df5a2fc7b575/0.0.0/2a88c45fed596f9421a2e7f74ab1a3cd012ef75210a5dc1950e8d60ca8d9c66c)\n",
      "100\n",
      "100\n",
      "0.19607938757312063\n"
     ]
    }
   ],
   "source": [
    "!python run_bleu_v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038dd31",
   "metadata": {},
   "source": [
    "## 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b11006eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from modeling_cpt import CPTModel, CPTForConditionalGeneration\n",
    "\n",
    "model = CPTForConditionalGeneration.from_pretrained(\"output/hk01/6\")\n",
    "tokenizer = BertTokenizer.from_pretrained('output/hk01/6')\n",
    "\n",
    "#model_inputs = tokenizer(test_set[0]['article'], max_length=128, padding=\"max_length\", truncation=True,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c36ac101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def print_result(idx):\n",
    "    input_text = dataset['test'][idx]['article']\n",
    "    print(\"input: \",input_text)\n",
    "\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\",max_length=512)\n",
    "\n",
    "    #prompt_length = len(tokenizer.decode(inputs['input_ids'][0]))\n",
    "    #outputs = model.generate(inputs['input_ids'], max_length=64, do_sample=True, top_p=0.95, top_k=60)\n",
    "    outputs = model.generate(inputs['input_ids'], max_length=64, top_p=0.95)\n",
    "    generated = tokenizer.decode(outputs[0])\n",
    "\n",
    "    print(\"prediction result: \",generated)\n",
    "    \n",
    "    print ('label: ',dataset['test'][idx]['summarization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "753f6f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  美國知名基督教牧師葛培理博士（Dr. Billy Graham）周三（21日）逝世，眾人皆知這位以演說鼓舞千萬信徒的佈道家，也是慈愛的父親與「愛妻號」。他1943年與同學鍾路得（Ruth Bell Graham）結婚。這位讓他一見傾心的女子，原來在中國出生和成長，曾留學朝鮮。她一直心懷亞洲民眾，鼓勵並陪同丈夫先後在1988年和1992年到中國及朝鮮進行歷史性訪問。 葛培理和鍾路得由同學成為終身伴侶，一同經歷64個寒暑。（billygraham.org圖片） 鍾路得1920年6月10日出生於江蘇清江浦（今淮安市）。父親鍾愛華（L. Nelson Bell）任職外科醫生，跟母親Virginia McCue Bell都是美南長老會（Presbyterian Church in the United States）派到中國的醫療傳教士。鍾路得在五兄弟姊妹中排行第二。 她在1933年、即13歲時被送到朝鮮平壤讀中學。父母3年後休假，她隨雙親返回家鄉美國北卡羅來納（North Carolina）蒙特列特鎮（Montreat），在此完成中學課程。 鍾路得1937年秋季進入伊利諾伊州惠頓學院（Wheaton College）升學。同校攻讀人類學的葛培理憶起兩人邂逅情景：「我看見她在路上朝我的方向走來的時候，我的視線無法移開。她望向我，我們視線相接，而我肯定她是我想娶的女人。」 葛培理雖然因為工作經常不在家，鍾路得靠書信和講電話與丈夫維繫感情。（billygraham.org圖片） 兩人大學畢業後不久就決定相守終生。他們1943年8月13日成婚後也選擇在蒙特列特鎮組織家庭。夫妻倆育有二子三女。由於葛培理經常在外工作，教育子女的重擔落在她身上。 她不僅是葛培理的賢內助，更是他事業路上的夥伴。1950年《抉擇時刻》（Hour of Decision）開始廣播，節目名稱便是她的手筆。鍾路得在中國成長與朝鮮受教育的背景，讓她對亞洲人懷有特殊深厚的感情，葛培理先後在1988年和1992年對中國和朝鮮訪問，鍾路得功不可沒。 夫婦倆1996年雙雙獲頒美國國會金章獎（Congressional Gold Medal），以表揚他們在德育、種族平等、家庭、公益和宗教事務的貢獻。 葛培理曾大讚妻子鍾路得肩負照顧兒女重擔，令他可以工作時得心應手。（billygraham.org圖片） 兩人攜手度過64個寒暑後，鍾路得2007年6月14日在家中去世，他的哀痛可想而知。他在悼念亡妻的講話中指出：她是他遇過最不可思議的女子，不但聖經知識淵博、是極棒的媽媽，對教會與社區也是全心投入。在老伴快將先走一步之際，他表示雖然會很想她，但想到有天兩人會在上帝跟前重聚，便會感欣喜。 一眾孫兒來訪，葛培理夫婦當然樂在其中。（billygraham.org圖片）\n",
      "prediction result:  [SEP] [CLS] 美 國 知 名 基 督 教 牧 師 葛 培 理 博 士 （ dr. billy graham ） 週 三 （ 21 日 ） 逝 世 ， 眾 人 皆 知 這 位 以 演 說 鼓 舞 千 萬 信 徒 的 佈 道 家 ， 也 是 慈 愛 的 父 親 與 「 [SEP]\n",
      "label:  他在工作以外，也是慈愛的父親與「愛妻號」，學生時代邂逅同窗鍾路得，自此同渡超過60寒暑，這位讓他一見傾心的女子，原來和亞洲淵源甚深\n"
     ]
    }
   ],
   "source": [
    "print_result(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d2c4510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  比利時布魯塞爾時間7月21日上午5時31分，歐洲理事會主席米歇爾（Charles Michel）在Twitter上推出「搞定！」（Deal!）一語，為這場原訂在17至18日完事、最後卻連續開了近90個小時的歐盟預算峰會劃上句號。在歐盟27國領袖五日四夜幾乎日夜不眠、每晚開會到日出的努力下，2020至2027年總值1.074萬億歐元的預算有了着落，而且首次由歐盟共同大額舉債融資、總值7,500億歐元的疫後「復蘇基金」也最終順利過關。 跟普遍的領袖峰會不同，歐盟國家數目太多，國與國之間的政治爭議繁瑣，難以先由級別較低的官員或技術官僚敲定細節再由各國領袖從容簽名。因此，各國領袖徹夜開會的情況其實並不罕見。不過，這次預算峰會也算是「表現突出」：對上一次歐盟各國連續開會超過90小時的情況要數到2000年的法國尼斯（Nice）峰會——當年歐盟15國的峰會，就為其後將歐盟擴展至今天27國鋪設了至今也極具爭議的決策權力分配機制。 會議是「廿年最長」還是「史上最長」？ 對於這次預算峰會有沒有打破當年的紀錄，如今儼如「節儉五國」（Frugal Five）之首、一直在各種層面反對「復蘇基金」的荷蘭首相呂特（Mark Rutte），與「復蘇基金」的主要受助國意大利總理孔特（Giuseppe Conte）也有不同意見。 在絕大多數國家都支持復甦基金的情況下，荷蘭首相呂特成為了這次峰會的反派主角。（美聯社） 意大利總理孔特，在歐盟通過復甦基金的無償資助後，大概可揭穿自己的親歐派面目。（美聯社） 這次幾乎獨力使會議由兩天變成五天的呂特表示，他曾經請示米歇爾他應否在峰會的最後時刻多講幾句，讓會議能打破尼斯峰會的時間紀錄，不過最後孔特卻拿了發言權。然而，最終會議大約在上午5時45分完結，呂特就指這次會議「最終完結得早了一些」。與呂特在預算問題上爭持不下、日前曾痛批呂特只能在荷蘭國內「當幾天英雄」的孔特，卻指會議很可能打破了尼斯峰會的時間紀錄。 根據追蹤歐盟多年的一位記者計算，這次疫情後各國領袖首次親身出席的峰會從17日的上午10時，一直開到21日的上午5時45分，總共91小時45分；而尼斯峰會由當年12月7日的上午9時45分，一直開到11日的上午5時30分，也剛好總長91小時45分。因此，呂特與孔特兩人皆錯。（不過尼斯峰會的時間是否要包括當時其他正要加入歐盟的國家領袖的會議，卻是另一可能爭端。） 當然，呂特與孔特之間在領袖們看着日出開香檳時的會後小爭議，只屬輕鬆笑談。不過，此等笑談之所以能出現，卻顯示出會議成果似乎讓所有人都能滿意。 疫情使預算峰會難上加難 其實，即使沒有新冠疫情的影響，這次預算峰會本來就預計會是困難重重。首先，這是英國脫歐之後的首次歐洲七年預算。英國退出讓預算每年出現大約100億歐元的空洞，要由各國填補。這就挑動了歐盟的「南北之爭」：以德國為首的北方財政穩健國家一直希望以壓低預算總額解決問題；而中、南歐等受助國則希望財政穩健的國家付出更多。 歐羅巴大廈的歐洲理事會全體會議場地雖大，卻有侷促之感。（美聯社） 另外，近年每年從歐盟預算獲得高達其國內生產總值（GDP）數個百分點資助的波蘭和匈牙利，一直被歐盟委員會指責侵犯法治，甚至展開或計劃展開《歐盟條約》第七條的制裁行動。可是，第七條的制裁卻要歐盟其他成員國全體同意，落實極其困難，因此西歐各國都有聲音要利用這次預算的機會，加入「不必全體同意」的機制，利用預算資助的中止權去制裁波蘭、匈牙利等國。這種「東西之爭」，也早預計會讓這次預算峰會激起不少爭議——畢竟預算案是須要全體同意的。 經歷過新冠疫情的衝擊後，德國等財政穩健國家救市「銀彈充足」，相較之下，受疫情打擊更嚴重的意大利、西班牙、法國等卻難以在不大增舉債成本的前提下大刀闊斧的救市；如此情勢，歐盟各國經濟發展的差距只會愈來愈大，使歐元區甚至歐盟更難維持。 於是，到了5月，此前一直反對歐盟共同舉債、反對歐盟無償資助各國抗疫救市的德國總理默克爾（Angela Merkel）就來了一個「華麗轉身」，站到法國總統馬克龍（Emmanuel Macron）、意大利總理孔特、西班牙首相桑切斯（Pedro Sanchez）等領袖一方，支持成立5,000億歐元的復蘇基金，以提高歐盟委員會預算空間（Headroom）的方式去進行舉債，並無償資助受疫情打擊嚴重的國家。 法德聯合陣線在這次峰會上展露無遺。（美聯社） 德國改變取態，卻不代表復蘇基金已成定局。在歐盟委員會主席馮德萊恩（Ursula von der Leyen）同月接納德法主張，並為之加上2,500億的貸款資助份額後，由丹麥、荷蘭、瑞典、奧地利組成的「節儉四國」（Frugal Four）就馬上聲言反對。其中，來年3月就要面對大選的荷蘭首相呂特，更成為了反對復蘇基金的領軍人物。 四處惹火的荷蘭首相 7月17日，剛抵達布魯塞爾的呂特已拉開戰幔，聲稱他認為「我們達成共識的或然率低於50%」，又警告「（共識）內容比速度重要」。不過，對於曾經在教會講道時聲稱他有51%確定上帝存在、有49%感到懷疑的呂特此刻的表態，外界也是半信半疑——畢竟「節儉國」失去了德國這個盟友可算是深受重創，區區荷蘭又能如何面對德法同盟的施壓呢？ 然而，手握預算否決權的呂特卻果真是立場堅定，而且四處「惹火」。首先，節儉國雖然已忍痛接受共同舉債的安排，卻堅決要在無償資助與有償貸款的比例動手，要求至少將無償資助的金額減少2,000億歐元。 五日峰會之後，呂特得益不淺，會後尚有氣力與米歇爾、馬克龍、馮德萊恩等人商談。（美聯社） 其次，由於共同舉債意味着南方受助國的開支要由北方節儉國的納稅人結帳，本着「無代表不納稅」的精神，呂特要求任何歐盟國家在復蘇基金的具體運用上面也應該有否決權，因此只要有任何節儉國不同意，受助國就不能夠得到一分一毫。 同時，呂特也要求歐盟增大英國前首相戴卓爾夫人（Margaret Thatcher）時代遺留下來的預算回扣金額，讓節儉國的實際付出比預算上的銀碼為低。 最後，呂特和奧地利總理庫爾茨（Sebastian Kurz）也公開堅持預算中的資助要加入法治要求，劍指波蘭、匈牙利等國。 在呂特戰線已劃的背景下，年僅34歲的芬蘭女總理馬林（Sanna Marin）在峰會上也「非正式」的加入了荷蘭等國陣營，因而「節儉四國」突然擴張成「節儉五國」，使呂特的否決態勢更為堅定。 年僅34歲的芬蘭女總理馬林在峰會上造就了「節儉五國」的新形勢。（美聯社） 一向在歐盟層面上與默克爾「形同母子」的奧地利總理庫爾茨，此次留在「節儉國」一方，卻顯得特別獨單。（美聯社） 匈牙利總理歐爾班曾威脅要否決預算，不過預計仍為匈牙利爭得更多資助的他「見好便收」，會後更宣稱他是個老人家，「這並非我的第一次峰會」，指這是他的成功「秘密」。（美聯社） 對於上述種種要求，意大利總理孔特就堅持原來的5,000億無償資助金額已是「最低水平」，指責呂特只能當幾個禮拜英雄，隨後就會被全歐洲民眾責難；法國總統馬克龍則堅持無償資助金額不能低於4,000億歐元，又指「你們可能以為我主張無償資助是個瘋子，不過現在連安吉拉（按：Angela，即默克爾的名字；歐盟領袖為表親切慣以名字相稱）也支持我了」；馬克龍又因庫爾茨在會上外出接電話而指責後者「根本不在乎」歐盟前途。 除了這道南北戰線，在東西戰線之上，被預算「法治要求」所針對的波蘭總理莫拉維茨基（Mateusz Morawiecki）指此等要求是「較強國家勒索其他國家的工具」；匈牙利總理歐爾班（Victor Orban）除了稱此等要求讓他想起以前的共產政權之外，也批評指「我不知道荷蘭總理憎恨我或者匈牙利，是出於什麼個人原因」。 身處戰線外圍的盧森堡首相貝特爾（Xavier Bettel），在峰會中途回國主持新冠疫情會議之前，就指他過去7年也重未見過在眾多的問題上各國會有如此對立的立場。 連夜未眠的會議後，默克爾見記者時雙眼充滿紅絲。（美聯社） 巧妙逢迎各國的最終共識 此等形勢之下，在聯邦黨派紛亂、地方勢力強大的祖國練就得一身和解政治本領的比利時前首相兼現任歐洲理事會主席米歇爾，就扮演了重要的中間調解角色。他除了在較少人關注的復蘇基金中的科學開支、農業支出、環保計劃等項目作出細緻調整去取悅呂特的節儉國領袖之餘，更積極邀請各國領袖到他辦公室景色宜人的陽台上作小組談判——這種談判就成了這次峰會的主軸。 最後，經過四日的努力，加上兩晚明顯的徹夜不眠（會議最後兩晚的全體會議都一度設定於清晨四、五時左右舉行），共識終得達成。 會議有成，歐洲理事會主席米歇爾應記一功。本次預算除了開了歐盟巨額共同舉債的先例，還將計劃在塑膠徵費、碳邊境機制、碳排放交易系統、數碼稅、金融交易稅等項目增加歐盟的財政收入。（美聯社） 米歇爾在其陽台上接待波蘭總理莫拉維茨基。（美聯社） 米歇爾辦公室的陽台成為了這次峰會的重要會面場地。（美聯社） 相較之下，歐盟委員會主席馮德萊恩，就沒有在這次峰會上扮演明顯的遊說角色。（美聯社） 首先，總值7,500億歐元的復蘇基金——現已改稱為「未來一代的歐盟」（Next Generation EU）——維持既有金額。不過，無償資助的部份下降為3,900億，絕大部份為至關重要用作投資振興經濟的項目；而貸款部份則上升至3,600億。如此，一方面各受助國可得滿意結果，另一方面節儉國也能向國內選民展現他們如何成功壓下馬克龍的4,000億底線。 其次，在規管復蘇基金應用的層面，27國共識列明，在例外的情況下，一國可提出爭議，不過歐洲理事會會在3個月內以多數決（而非共識制）的形式作出判決，因此沒有任何國家可對基金的應用有否決權。如此，一方面大多數原本就支持復蘇基金的國家就不用擔心其應用將來會被掣肘，另一方面「節儉五國」也可以此「制衡機制」去向國內納稅人交代。 同時，新預算也增加了對「節儉四國」的預算回扣，同時也增加了各國可保留的關稅份額——歐洲最大的港口鹿特丹港（Port of Rotterdam）「剛好」位於荷蘭——也算是滿足了節儉國的願望。 在全體會議之時，各國領袖竟然要拿着「新鮮出爐」的預算文件細閱詳情。此等外交談判的形式，大概不太適合大西洋彼岸的某位大國領袖。（美聯社） 最後，歐盟預算中原本清楚列明的法治要求機制，也變成了「保護預算與『未來一代的歐盟』的條件性機制」，未來將由歐洲理事國以多數決決定。由於此句的上一段「剛好」列明「歐盟財政利益」與「對法治的尊重」的重要，加上多數決而非共識制的「條件性機制」，這實際上已表明預算已加入了法治要求。不過，行文如此，波蘭和匈牙利也可以挽回一些面子，不用接受西歐的「法治教育」。 在各方多面向的妥協之下，這次疑為史上最長的歐盟峰會隨着布魯塞爾的日出而閉幕。這次為了抗疫而落實的一次性共同舉債措施，最終會否將歐盟推向一個財政同盟，我們尚難輕言。不過，出自對呂特要求讓步的復蘇基金應用監管機制，卻似乎無可避免會增加了歐盟委員會與歐州理事會管控成員國財政政策的能力。這一套機制，如果能發展下去，難說不會成為未來財政同盟的一個重要基礎。歷史發展充滿意外，若果歐盟整合成功，他朝人們回頭一望，如今扮演攔路虎角色的呂特，未來也並非沒有可能成為歐洲財政聯盟的歷史英雄。\n",
      "prediction result:  [SEP] [CLS] 歐 盟 27 國 領 袖 幾 乎 日 夜 不 眠 、 每 晚 開 會 到 日 出 的 努 力 下 ， 2020 至 2027 年 總 值 1. 074 萬 億 歐 元 的 歐 盟 的 預 算 有 了 落 ， 而 且 首 次 由 歐 盟 共 同 大 額 舉 [SEP]\n",
      "label:  歐盟預算峯會原訂在17至18日完成，最後卻連續開了近90個小時，在27國領袖五日四夜幾乎日夜不眠、每晚開會到日出的努力下，終於達成共識，讓這個由歐盟共同大額舉債融資、總值7,500億歐元的疫後「復蘇基金」順利過關\n"
     ]
    }
   ],
   "source": [
    "print_result(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "40c17479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  西班牙大選結束，目前點票結果顯示首相桑切斯所屬的工人社會黨勝出，但無法取得過半數議席。另一方面極右呼聲黨取得更多議席成為第三大黨，選舉結果顯示政治僵局仍難以打破。 工人社會黨支持慶祝選舉取得勝利，但這次選舉結果與上次差不多，難以為執政黨取得突破。（路透社） ↓↓↓想看更多西班牙加泰羅尼亞示威照片，請點擊放大觀看： 大約500名示威者11月11日在拉宏格亞市（La Jonquera）的邊界一帶封堵連接加泰羅尼亞與法國的交通要道AP-7高速公路，目的是促使西班牙明白，坐下來對談是唯一的解決方法。（Reuters） 有示威者在高速公路旁架起睡床休息。（Reuters） 警方排成一條橫線。（Reuters） 警方與堵塞公路的示威者溝通。（Reuters） 這次是西班牙4年以來第四次議會選舉，也是今年第二次。根據目前點票結果顯示，首相桑切斯（Pedro Sanchez）所屬的工人社會黨勝出，得120席。但不僅無法取得國會過半數，還要較大選前少數席。 而極右的呼聲黨（Vox），則憑着加泰羅尼亞危機的呼聲，議席增加一倍至56席，成為這次選舉中的另一個大贏家。 僵局依然難以打破 自2015年後西班牙出現多個新政黨，打破國內傳統左右翼政黨輪替的格局，國會始終無法籌組穩定聯合政府，觸發一次又一次的大選。2019年4月西班牙剛大選結束，因工人社會黨無法取得過半數議席，亦無法拉攏其他政黨支持，籌組聯合政府失敗，導致要一年內二度舉行大選。 極右呼聲黨得助於加泰羅尼亞危機，取得更多右翼選民的支持。（路透社） 觀看目前狀況，西班牙政治局勢仍然沒有改善跡象，工人社會黨仍需要與其他政黨尋求組成聯合政府。儘管極左政黨「我們能」黨（United We Can）願意提供協助，但兩黨總合起來只有146席，仍缺17席才能取得過半數。 目前工人社會黨需與支持加泰獨立的左翼政黨合作才可籌組聯合政府，但外界認為這選項並不可行。假若籌組政府失敗，西班牙將要再次舉行大選。 加泰危機放大右翼聲音 呼聲黨黨魁阿巴斯卡（Santiago Abascal）表示他們的反移民政策及推動的文化與政治變革獲得認同。阿巴期卡稱他們成功公開討論各種禁忌，並告訴左翼政黨他們並不處於道德高地。 10月中，西班牙最高法院以煽動叛亂罪，判處9名鼓吹加泰獨立人士監禁，激發加泰發生暴力示威。判決並促使西班牙右翼政黨要求桑切斯作出嚴厲的回應，同時成為呼聲黨的宣傳機會，讓他們獲得更多支持。\n",
      "prediction result:  [SEP] [CLS] 西 班 牙 大 選 週 三 （ 11 日 ） 結 束 ， 目 前 點 票 結 果 顯 示 首 相 桑 切 斯 所 屬 的 工 人 社 會 黨 勝 出 ， 但 無 法 取 得 過 半 數 議 席 。 另 一 方 面 極 右 呼 聲 黨 取 得 更 [SEP]\n",
      "label:  西班牙舉行年內第二次大選。點票結果顯示，看守首相桑切斯（Pedro Sanchez）所屬的工人社會黨勝出，不過仍未能夠獲得過半數議席，所得議席甚至比起上一次大選減少。另一方面極右呼聲黨取得更多議席成為第三大黨，選舉結果顯示政治僵局仍難以打破\n"
     ]
    }
   ],
   "source": [
    "print_result(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6b05612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  美國前總統克林頓（Bill Clinton）與白宮前實習生萊溫斯基（Monica Lewinsky）於1998年爆出性醜聞。時隔23年，這宗陳年戀聞因為萊溫斯基於2021年5月21日的一個Twitter推文再被炒熱。 克林頓與萊溫斯基：圖為2019年5月13日，美國白宮前實習生萊溫斯基在美國紐約市出席活動。（Getty） 克林頓與萊溫斯基：圖為2018年10月18日，美國前總統克林頓在Facebook發布自己的照片。（President Bill Clinton Facebook專頁） 克林頓與萊溫斯基：圖為2021年5月13日，美國前總統克林頓（中）在Twitter發布自己的照片。（Bill Clinton Twitter帳號） 克林頓與萊溫斯基：圖為2018年12月5日，美國白宮前實習生萊溫斯基在美國洛杉磯的活動上發言。（\n",
      "Getty） 克林頓在任總統期間，與白宮見習生萊溫斯基有一段「不恰當關係」，更差點令他被彈劾下台。（Getty Images） 當年萊溫斯基只有22歲。（Getty Images） 美國前總統克林頓雖逃過被彈劾的命運，然而他與萊溫斯基的醜聞，已在他的人生中留下污點。（路透社） 希拉里可算是最關心政治的第一夫人，丈夫克林頓與實習生萊溫斯基有染後，令希拉里化悲憤為力量，在丈夫卸任後專心在政途上向上游。（Getty Images） 網絡應用程式UberFacts在Twitter上問網民：「你做過最高風險、但最低回報的事情是甚麼？」 👀 https://t.co/lrr5eCeCsA — Monica Lewinsky (she/her) (@MonicaLewinsky) May 21, 2021 萊溫斯基2021年5月21日轉發UberFacts的推文，並以「碌大對眼」的表情符號回答UberFacts的問題。 這個表情符號可代表側目而視、暗示一個人正逃避一個訊息、或需要一段長時間來回應一條令人尷尬的問題。因此，她的回應令人聯想到，她是指與克林頓發生婚外情，是她做過最高風險、但最低回報的事。 有UberFact的「妙問」，又有萊溫斯基的「妙答」，Twitter迅即為此沸騰起來，更一度登上熱門搜尋排行榜。 You win Twitter for the day — The_Sofa_King_Black_Vote (@WalterBailey17) May 21, 2021 她的回應在數小時內得到144,000個「讚好」和差不多3萬次轉發。很多網民以代表大笑的表情符號回應萊溫斯基的推文。 You have won Twitter for the year. https://t.co/IY923sBcSe — Chris Hahn (@ChristopherHahn) May 21, 2021 Twitter帳號名稱為The_Sofa_King_Black_Vote的網民2021年5月21日稱她已拿下本日推文之最的名銜，而帳號名稱為Chris Hahn的網民更指，她的推文是年度推文之最。 克林頓與萊溫斯基傳出有染時，克林頓本來一直矢口否認和萊溫斯基有性關係。但最後劇情因萊溫斯基提供一條被驗出沾有克林頓精液的藍裙而逆轉。克林頓因作假證供和妨礙司法公正而遭到彈劾。彈劾訴訟於1999年初開始，克林頓雖然最終被判無罪，但性醜聞已令他名譽掃地。\n",
      "prediction result:  [SEP] [CLS] 美 國 前 總 統 克 林 頓 與 白 宮 前 實 習 生 萊 溫 斯 基 於 1998 年 爆 出 性 醜 聞 後 ， 於 2021 年 5 月 21 日 的 一 個 twitter 推 文 再 被 炒 熱 ， 這 宗 陳 年 戀 聞 因 為 萊 溫sl 基 的 一 [SEP]\n",
      "label:  美國前總統克林頓（Bill Clinton）與白宮前實習生萊溫斯基（Monica Lewinsky）1998年爆出性醜聞，他本來一直矢口否認與她有性關係，但劇情最後因她提供一條被驗出沾有克林頓精液的藍裙而逆轉。克林頓因作假證供和妨礙司法公正而遭到彈劾。時隔23年，這宗陳年戀聞再度因為她的一個Twitter推文再被炒熱\n"
     ]
    }
   ],
   "source": [
    "print_result(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bd64403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  日前網民Sam Ho在「新手假日行山群組」發帖，指2月7日行經河背水塘時，見到有人違例放生。他向記者表示，當天下午約2時半經過該處，見到一名男子駕車將一個個發泡膠箱運到現場，從箱中取出一袋袋生物，並將牠們倒入水塘，當中包括了水魚、黃鱔和田雞。從相中可見，大量的田雞落入水塘後均見「反肚」，似已奄奄一息。\n",
      "\n",
      "有途人經過與放生男子爭執\n",
      "根據水務署資料，在水塘「放生」違反《水務設施條例》第30條，一經循簡易程序定罪，可處第五級罰款（最高為港幣五萬元）及監禁兩年。Sam指，當時有途人經過與該名男子爭執，亦有職員從漁護署車輛走下了解事件，據知職員曾致電通知上司，但半小時後仍沒有行動，最後不了了之；而該名男子曾自稱是甲龍村原居民，一年均會到上址幾次進行放生。而事件引起一眾山友擔心，動物死屍會否帶來其他疫症。\n",
      "\n",
      "生態教育及資源中心科學事務經理張瑪珊指，胡亂放生對生態方面有很大影響。她指出，雖然田雞、水魚、黃鱔都是淡水生物，但牠們多由市場購入，在運輸的過程中很可能會受傷或者生病，基本上不適合於水塘放生，而且平日食用的田雞大部分不是原生的虎皮蛙，假如將之放生，有機會在本地生態中引入外來物種。\n",
      "\n",
      "\n",
      "張補充指，「首先如果佢哋唔適應本地生態，可能會即刻就死；如果冇即刻死，喺水塘中佢哋可能同本地物種發生競爭，影響水塘嘅生態平衡。」張瑪珊表示，如果動物不能適應水塘環境而死去，屍體會腐爛影響水質，亦分解成養分，刺激藻類生長甚至爆發，之後影響水塘的含氧量並殺死其他水中生物。此外，如動物大量死去，牠們有機會在分解過程之中滋生細菌，讓生活中於水塘中的魚類染病；而一些本來已經染病的動物，將牠們「放生」便有機會將不同嘅病菌帶入水塘中，使當中的動物染病。\n",
      "張認為，長遠而言，政府應該立法規管放生行為，需有效地監控用以放生的物種，從而防止不適當的外來物種被人放生，以及有人因為放生而濫捕瀕危的物種。\n",
      "\n",
      "\n",
      "漁護署人員回覆指，昨日（2月8日）駕駛工作車輛途經清潭水塘前往進行清潔工作時，有市民指有人在水塘進行放生活動。漁護署已即時聯絡相關郊野公園職員到場處理，並留在現場等候，期間曾嘗試勸止但不成功，涉事人約半小時後自行離去。該署郊野公園職員到場，並與在場人士了解事件經過，指會繼續留意該處的情況，亦會就有人在水務設施進行放生活動，轉介相關部門跟進。\n",
      "漁護署一向不鼓勵市民於野外放生動物，並透過各種渠道加強教育及宣傳。如職員巡邏郊野公園時，發現放生活動，會即時勸止。\n",
      "prediction result:  [SEP] [CLS] 新 型 肺 炎 （ 俗 稱 武 漢 肺 炎 ） 疫 情 持 續 ， 不 少 人 都 會 到 本 地 進 行 「 放 生 」 。 近 日 有 網 民 駕 車 將 一 袋 袋 發 泡 膠 箱 運 到 河 背 水 塘 ， 並 將 牠 們 倒 入 水 [SEP]\n",
      "label:  一些宗教團體和善信定期都會舉行放生活動，不過胡亂「放生」，隨時令動物枉死變「殺生」。日前有市民行經元朗河背水塘時，發現有人將一袋袋的黃鱔、田雞及水魚等倒進水塘內「放生」，惟動物落到水塘全都「反肚」，令人擔心在武漢肺炎的疫情之下會再散播病毒。專家表示，如動物大量死去，有機會在分解過程之中滋生細菌，將不同的病菌帶入水塘中，認為政府應該立法規管放生行為，防止不適當的外來物種被放生。\n"
     ]
    }
   ],
   "source": [
    "print_result(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9310aead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  英國外交大臣藍韜文（Dominic Raab）香港時間3月17日晚上出席美國阿斯彭安全論壇的虛擬論壇時稱，英國在地球、全球經濟，生態系統有道德責任以及不可分割的利益。惟英媒前一天（16日）報道被人秘密錄音的內容，他稱英國想與違反人權問題的國家做生意。他說因人權問題而限制英國的貿易，意味國家會錯過「增長市場」。此舉惹來部分政界人士批評。 《赫芬頓郵報》16日報道藍韜文的視像會議錄音，當時他面向外交、國協及發展事務部（Foreign, Commonwealth and Development Office）職員，在一個問答環節發言。他稱堅信英國應在全球範圍自由貿易。他說如英國限制自己僅與符合歐洲人權公約的國家做生意，國家未來將不會與「增長市場」有很多貿易協議。 他稱：「我們不會因為（與特定國家）有問題而破壞彼此關係——我們對話因我們想改變（它們的）行為。」（“We don’t junk whole relationships because we’ve got issues – we have a conversation because we want to change the behaviour.\"） 藍韜文的錄音，被批與他對外表達英國捍衛人權的說法大相庭徑。 約翰遜拒絕採用中國政府在新疆地區犯下「種族滅絕和反人類罪」這一說法，主導英國下議院否決相關提案。圖為2020年12月19日，英國首相約翰遜召開記者會。（Reuters） 《赫芬頓郵報》稱他的這番言論之前，英國政府16日公布《置身競爭時代的全球化英國：安全、國防、發展與外交政策綜合審查》（Global Britain in a Competitive Age: the Integrated Review of Security, Defence, Development and Foreign Policy）這份政策文件。有英國政界人士稱，內文顯示英國低調處理中國的問題。 藍韜文在阿斯彭安全論壇的言論，似是回應有關批評。有記者問他，為何英國推進與中國建立更緊密聯繫，這與美國拜登政府取態有異。他說：「我們是這樣看事情：中國是已然存在（China is here to stay）。」 他說：「我不相信我們會重提冷戰思維或範式。」他稱：「我們是正面的，以及我們應（與中國）尋求在一些範疇有建設性的互動，顯然是商業與貿易。」 他指出人人「多多少少都在與中國做生意。」 仍重視與華貿易 英國首相約翰遜（Boris Johnson）曾形容《置身競爭時代的全球化英國：安全、國防、發展與外交政策綜合審查》這份逾百頁報告，是冷戰結束後「（對英國外交和防務政策）最大最全的一次評估」。它展現未來10年英國對本國在全球事務上所扮演角色之願景，以及英國2025年前所採取的行動。」 文件內容指出，英國須尋求與中國建立正面的經濟關係，包括「更深的貿易連繫以及更多中國投資。」它又指出「我們擁抱市場力量，以及我們重視與中國的貿易。 但是，我們亦將與現有盟友和以及高度信任供應商建立新的合作夥伴關係。」 01新聞\n",
      "prediction result:  [SEP] [CLS] 英 國 外 交 大 臣 藍 韜 文 3 月 17 日 晚 上 出 席 美 國 阿 斯 彭 安 全 論 壇 的 虛 擬 論 壇 時 稱 ， 英 國 在 地 球 、 全 球 經 濟 ， 生 態 系 統 有 道 德 責 任 以 及 不 可 分 割 的 [SEP]\n",
      "label:  英國媒體爆料，英國外相藍韜文一段祕密錄音流出，他稱英國想與違反人權問題的國家做生意，若因人權問題而限制英國的貿易，意味國家會錯過「增長市場」。此舉惹來部分政界人士批評......\n"
     ]
    }
   ],
   "source": [
    "print_result(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b5c0a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  台觀光局指出，先前已宣布2月1日至29日暫停旅行業組團前往中國大陸地區旅遊（含轉機前往其他地區旅遊）。為配合台疾病管制署提升港澳地區旅遊疫情等級為第二級，故2月6日起暫停台灣旅行社組團到港澳旅遊，但不含中轉港澳轉機到其他地區。台觀光局表示，持續配合台疾管署相關防疫作為，並視台疫情指揮中心發佈的疫情訊息綜合評估，隨時調整相關管制事宜。一、台籍人士：2月6日起，有陸港澳旅遊史者，需居家檢疫14天；申請獲准至港澳入境者，需自主健康管理14天。二、大陸人士：暫緩入境。三、港澳人士：2月7日起，入境後需居家檢疫14天。四、外籍人士：2月7日起，14天內曾經入境或居住於中國大陸、香港、澳門的外籍人士，暫緩入境。\n",
      "prediction result:  [SEP] [CLS] 因 應 新 型 冠 狀 病 毒 肺 炎 （ 俗 稱 「 武 漢 肺 炎 」 ） 疫 情 ， 台 灣 觀 光 局 今 天 （ 7 日 ） 宣 布 ， 暫 停 台 灣 旅 行 社 組 團 到 港 澳 旅 遊 ， 但 不 含 中 轉 港 澳 轉 機 [SEP]\n",
      "label:  考量武漢肺炎疫情持續擴散，台灣觀光局在2月6日宣布，即日起至2月29日，暫停台灣旅行社組團前往香港、澳門地區旅遊，但不包括從港澳轉機。\n"
     ]
    }
   ],
   "source": [
    "print_result(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ebd1ca1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  Apple Best of 2019 的 Apps 趨勢是用家說故事，而 Unfold 更是其中一個得獎應用程式。 Unfold 與我們平日用的執相 App不同，它並沒有美肌長腿功能，反而提供超過150種相框(當然有些需要課金～)，還有有動感的 GIFs，令到成品更多元化。\n",
      "\n",
      "不要以為免費相框便沒有好東西，免費相框大致可分為3類：一張圖加字、兩張圖及短故事，大家可以按需要選擇，然後再為相片更改大小，甚至加入濾鏡，張原圖的風格改變，例如 Reykir 將相片的啡黃色突出，會帶點秋意的感覺。處理相片後，便可以插入文字、貼圖和 GIFs，即使沒有課金，選擇亦有很多。不過有個小Tips給大家，在 Unfold 中是不能打中文字，但只要你在 App以外預先打好，然後Copy and Paste 便顯示句子。\n",
      "\n",
      "執圖後，可以選擇把成品儲存到手機，又或是直接上載到社交媒體，Facebook、Instagram 和 Snapchat，非常方便，除此以外，作為 App 版相簿的 Unfold 可以建立相簿，隨時可以重溫或修改相片。大家可以小上牛刀，先用免費版本的 Unfold，想進一步砌靚圖，再課金每年 HKD158 (或月費 HKD23)！\n",
      "prediction result:  [SEP] [CLS] 【 apple best of 2019 】 今 年 度 apps 趨 勢 ， 大 家 可 以 在 app 上 執 相 app ， 又 或 是 用 家 說 故 事 的 應 用 程 式 。 unfold 不 但 提 供 美 肌 長 腿 功 能 ， 反 而 提 供 超 過 150 種 [SEP]\n",
      "label:  今時今日除了 post 相需要執圖，post Story 也不可馬虎了事，假如你不需要每張相也美圖變瘦，以下這個App - Unfold ，可說是來年必備之選，2分鐘執相更可直接上載到社交平台，就讓呀脆跟大家分享一下！\n"
     ]
    }
   ],
   "source": [
    "print_result(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f112c42c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
